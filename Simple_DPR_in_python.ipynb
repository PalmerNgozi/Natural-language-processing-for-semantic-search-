{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple DPR in python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd3gvMCm+OjCYu58REytye"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtEhRnJJb7ET",
        "outputId": "d709ad4e-2377-4cee-fbc9-355724f4c6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 434 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRContextEncoderTokenizer as dct\n",
        "from transformers import DPRContextEncoder as dce"
      ],
      "metadata": {
        "id": "pH8HIO4ud0nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRQuestionEncoderTokenizer as dqt\n",
        "from transformers import DPRQuestionEncoder as dqe\n"
      ],
      "metadata": {
        "id": "6nLly_oogIj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# firstly, initialize tokenizers and models for both our context model and question model\n",
        "\n",
        "cntx_model = dce.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "cntx_tokenizer = dct.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "\n",
        "quest_model = dqe.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
        "\n",
        "quest_tokenizer = dqt.from_pretrained('facebook/dpr-question_encoder-single-nq-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul_PSyx5haGJ",
        "outputId": "da190c2c-aab1-4767-f2cb-7f8e6f596581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here i want to create some questions and answers to the questions. Take time here to create this, you basically need to ask a question and get a response. This will show why and how the dpr is different from sentence\n",
        "#transformers. So if i ask a question \"At what time will you be coming back tommorow ?\" i would not be expecting an anscwer such as \"I will  be coming back tommorow\" or \"We will see each other tommorrow\"\n",
        "# see it dosent answer the initial question. Feel free to add more here\n",
        "\n",
        "question = [\n",
        "            \"How old is your cat\",\n",
        "            \"will you be getting married\",\n",
        "            \"what is your favorite movie yet\",\n",
        "            \"when is the Queens birthday celebration\"\n",
        "]\n",
        "\n",
        "context = [\n",
        "           \"Of all my cousins, Ahmed is my favorite\",\n",
        "           \"I havent been to Paris yet\",\n",
        "           \"My cat is 3 years old\",\n",
        "           \"I have written a bestselling book\",\n",
        "           \"I wont be getting a cat yet\",\n",
        "           \"the queens birthday is in July\",\n",
        "           \"i will be getting married\",\n",
        "           \"My best movie is Lord of the rings\",\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Z2kCEyx3hwq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cntx_token = cntx_tokenizer(context, max_length=256, padding ='max_length',return_tensors='pt')\n",
        "#here we create our context embeddings\n",
        "cntx_embedding = cntx_model(**cntx_token)\n",
        "\n",
        "quest_token = quest_tokenizer(question, max_length=256, padding ='max_length',return_tensors='pt')\n",
        "quest_embedding = quest_model(**quest_token)"
      ],
      "metadata": {
        "id": "7keKXkuDkHPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quest_embedding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPayn45dlOpp",
        "outputId": "b31d48de-fb77-4903-da66-1adca54884be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quest_embedding.pooler_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYCfJdRoMP0",
        "outputId": "202422c0-881d-4812-bd81-4ea83fb24d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the requirement for running this example. if you already have this module feel free to skip this line of code\n",
        "\n",
        "#!pip install sentence-transformers\n",
        "\n",
        "#compare our query embeddings against our context embeddings to see which are the most similar with cosine similarity\n",
        "\n",
        "import torch\n",
        "from sentence_transformers.util import cos_sim as cs\n",
        "\n",
        "for i , quest_vect in enumerate(quest_embedding.pooler_output):\n",
        "  probs = cs(quest_vect, cntx_embedding.pooler_output)\n",
        "  argmax = torch.argmax(probs)\n",
        "  print(question[i])\n",
        "  print(context[argmax])\n",
        "  print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KksDHbB2oXI4",
        "outputId": "79c418e7-9165-487d-bf8c-e8577ba62305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How old is your cat\n",
            "My cat is 3 years old\n",
            "---\n",
            "will you be getting married\n",
            "i will be getting married\n",
            "---\n",
            "what is your favorite movie yet\n",
            "My best movie is Lord of the rings\n",
            "---\n",
            "when is the Queens birthday celebration\n",
            "the queens birthday is in July\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f15EiA8-pY8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}